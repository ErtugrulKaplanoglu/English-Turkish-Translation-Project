# Englishâ€“Turkish Translation Project  
Seq2Seq LSTM Prototype

This project aims to build a basic English-to-Turkish translation system using a Seq2Seq LSTM model.  
The dataset consists of cleaned parallel sentence pairs that are preprocessed and split into training, validation, and test sets.

---

## ğŸ“ Project Files
- **data_preparation.py** â€“ Preprocesses the dataset and creates train/val/test splits  
- **LSTM_Seq2Seq_prototype.py** â€“ Trains the Seq2Seq LSTM model  
- **train.en / train.tr** â€“ Training data  
- **val.en / val.tr** â€“ Validation data  
- **test.en / test.tr** â€“ Test data  

---

## ğŸ§  Model Overview
- Encoder: Embedding + LSTM  
- Decoder: Embedding + LSTM + Dense (softmax)  
- Tokenization with Keras `Tokenizer`  
- `<sos>` and `<eos>` tokens used for decoder sequences  
- Loss: Sparse Categorical Crossentropy  

---

## ğŸ¯ Purpose
This prototype provides the foundation for building a full translation system.  
Planned next steps include:
- Implementing the inference model  
- Adding an attention mechanism  
- Evaluating with BLEU score  
- Expanding the dataset  

---

## ğŸ“Œ Note
This README will be updated as the project evolves.
